---
title: "Practice Sheet 13"
author: "Park, Mia" # <--- Please change to your names here, format: "LastName, FirstName"
date: 'Due: Fri Oct 04 | 11:59pm'
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
editor_options: 
  markdown:
    wrap: 72
---

**APMA 3150 \| Fall 2024 \| University of Virginia**

<!--- Solution Region --->

```{css solution-region, echo=FALSE}
.solution {
    background-color: #232D4B10;
    border-style: solid;
    border-color: #232D4B;
    padding: 0.5em;
    margin: 20px
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

# [Exercises]{style="color:#FF7F50"}

## [Practice: recognizing hand written digits]{style="color:#FF7F50"}

Let's look at an example of artificial neural networks (ANN).

### Data preparation
   
The data is in `ElemStatLearn` package, but it is no longer available on the R package repository. So, we will need to download a compressed archive file and install it from there. Here are the three steps to load this package manually:

* Step 1: Run the code chunk below to download the data zip folder:
```{r}
url <- "https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/ElemStatLearn_2015.6.26.2.tar.gz"
destFilename <- "ElemStatLearn_2015.6.26.2.tar.gz"
download.file(url = url, destfile = destFilename)
```

* Step 2: under the "Packages" tab in RStudio, click "Install", and select "Install from: Package Archive File". Select the file you just downloaded; you should be able to find it in the same folder as this R Markdown file. Hit "Install", and wait until the Console is done with the installation.
  
* Step 3: Now, try to load the `ElemStatLearn` package.
```{r}
library(ElemStatLearn)
```
If you can load the library, you may delete the .tar.gz file. 

To implement a neural network algorithm, we also need the following packages:
```{r message=FALSE}
library(caret)
library(nnet)
```

Now, let's get started with the loaded data and view the first row.
```{r}
# Convert Row 1 of "zip.train" into a matrix
im <- matrix(as.numeric(zip.train[1,2:257]), nrow = 16, ncol = 16)
# Show the gray-scale picture for this matrix
image(t(apply(-im, 1, rev)), col=gray((0:64)/64))
```

From the picture above, you can tell it is "6", which matches the first component in Row 1.

### Neural network [work needed from you;)]

Now, we train a simple neural network. With `nnet` package, the activation function can only by the sigmoid function and there is only one hidden layer.

#### {.solution}
```{r result='hide', message=FALSE, warning=FALSE}
# Complete the codes in this chunk.
trainZip = data.frame(zip.train) # Variable "trainZip" is the data frame of the raw data "zip.train"
trainZip$X1 <- as.factor(trainZip$X1) # Factorize the response column (first column)

# Cross-validation method and number of resampling iterations.

tc <- trainControl("cv", 5)

# Create a data frame from all combinations of the supplied vectors or factors.
parameters <- expand.grid(.size = c(5),     # Number of units in the hidden layer
                          .decay = c(0.1))  # Regularization terms (for reducing model overfitting)

NN.fit <- train(
  X1 ~.,
  data=trainZip,
  method="nnet",
  trControl=tc,
  tuneGrid=parameters,
  MaxNWts=5000,     # The maximum allowable number of weights
  maxit=200        # The maximum number of iterations for neural network learning
)
```

Note the "value" printed every 10 iterations or "final value" represents the value of the loss, showing the “incorrectness” of each stage.

### Model evaulation

We can create a confusion matrix:
```{r}
table(Predicted = predict(NN.fit, trainZip[-1]), trainZip$X1)
```

Finally, let's check the neural network model accuracy, which is the ratio of correctly classified examples to the total number of examples.
```{r}
mean(predict(NN.fit, trainZip[-1]) == trainZip$X1)
```